# -*- coding: utf-8 -*-
"""cnn-covid-ct-images.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vE-bgkEV_O_XdEuvVeVS_mWmZ0Ron9zD

Import libraries and packages:
"""

!pip install tensorflow_addons

import numpy as np
import tensorflow as tf
import requests
import json
import shutil
import datetime
import os,glob
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib import cm
import seaborn as  sns
from sklearn.metrics import confusion_matrix

from itertools import cycle

from sklearn import svm, datasets
from sklearn.metrics import roc_curve, auc
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import label_binarize
from sklearn.multiclass import OneVsRestClassifier
from scipy import interp
from sklearn.metrics import roc_auc_score

from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.compat.v1 import ConfigProto
from tensorflow.compat.v1 import InteractiveSession
config = ConfigProto()
config.gpu_options.per_process_gpu_memory_fraction = 0.95
config.gpu_options.allow_growth = True
session = InteractiveSession(config=config)
import tensorflow_addons as tfa
from tensorflow.keras import Model
from tensorflow.keras.models import Sequential
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.losses import categorical_crossentropy
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout
from tensorflow.python.client import  device_lib
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from tensorflow.keras.preprocessing.image import load_img
from tensorflow.keras.applications.imagenet_utils import preprocess_input

"""Download images .zip from repository:"""

ct_images_dir = 'ct-images'
!rm -r ct-images
os.makedirs(ct_images_dir)

# Download url of non-COVID CT scans.
!wget --no-check-certificate https://github.com/deborawendland/cnn-covid-ct-images/raw/main/data/CT_COVID.zip -O covid.zip
!wget --no-check-certificate https://github.com/deborawendland/cnn-covid-ct-images/raw/main/data/CT_NonCOVID.zip -O noncovid.zip

!unzip covid.zip -d  ./ct-images && mv ./ct-images/CT_COVID/ ./ct-images/covid
!unzip noncovid.zip -d  ./ct-images && mv ./ct-images/CT_NonCOVID/ ./ct-images/noncovid

!rm *.zip

"""Split the files into two groups: train, validation and test:




"""

!rm -r data-split/

data_split_dir = 'data-split'
os.makedirs(data_split_dir)

url = 'https://github.com/deborawendland/cnn-covid-ct-images/raw/main/data/data_split/'

files = {
    'train': [
        'trainCT_COVID.txt',
        'trainCT_NonCOVID.txt'
    ],
    'validation': [
        'valCT_COVID.txt',
        'valCT_NonCOVID.txt'
    ], 
    'test': [
        'testCT_COVID.txt',
        'testCT_NonCOVID.txt' 
    ]
}

for stage in files:
  count = 0
  for file in files[stage]:
    request_url = url + file
    r = requests.get(request_url)
    open('./{dir}/{file}'.format(dir=data_split_dir, file=file), 'wb').write(r.content)
    count = count + len(open('./{dir}/{file}'.format(dir=data_split_dir, file=file), 'r').readlines())
  print ('{}: {}'.format(stage, count))

total = 0
for stage in fil:
  for file in fil[stage]:
      total = total + len(open('./{dir}/{file}'.format(dir=data_split_dir, file=file), 'r').readlines())
print ('total: {}'.format(total))

"""* Separates files into train, validation and test folders"""

!rm -r ./ct-images/train
!rm -r ./ct-images/validate
!rm -r ./ct-images/test
!rm data.json

data = {
    'train': {
        'covid': [],
        'noncovid': []
    }, 
    'validation': {
        'covid': [],
        'noncovid': []
    },
    'test': {
        'covid': [],
        'noncovid': []
    }
}

for stage in files: 
  for file in files[stage]:
    content = open('./{dir}/{file}'.format(dir=data_split_dir, file=file), 'r').readlines()
    if 'NonCOVID' in file:
      for line in content:
        data[stage]['noncovid'].append(line.replace('\n', ''))
    else:
      for line in content:
        data[stage]['covid'].append(line.replace('\n', ''))

with open("data.json", "w") as txt_file:
  json.dump(data, txt_file)
  

for stage in data:
  for case in data[stage]:
    try:
      os.makedirs('{dir}/{stage}/{case}'.format(dir=ct_images_dir,
                                                stage=stage,
                                                case=case))
    except:
      pass
    for file in data[stage][case]:
      shutil.move('{dir}/{case}/{file}'.format(dir=ct_images_dir,
                                               case=case,
                                               file=file), 
                  '{dir}/{stage}/{case}/{file}'.format(dir=ct_images_dir,
                                                       stage=stage,
                                                       case=case,
                                                       file=file))
      
        
!rm -r ./ct-images/covid
!rm -r ./ct-images/noncovid

"""Import train, validation and test info:"""

with open('data.json') as json_file:
    data = json.load(json_file)

for stage in data:
  for case in data[stage]:
    print ('Total images: {stage} - {case}: {count}'.format(stage=stage,
                                                            case=case,
                                                            count=len(data[stage][case])))

"""Preprocessing stage:"""

train_datagen = ImageDataGenerator(rescale=1/255) 
validation_datagen = ImageDataGenerator(rescale=1/255)

train = train_datagen.flow_from_directory(
        './ct-images/train/',
        target_size=(227, 227), 
        class_mode='categorical')

validation = validation_datagen.flow_from_directory(
        './ct-images/validation/', 
        target_size=(227, 227), 
        class_mode='categorical')

print("Batch Size for Input Image : ",train[0][0].shape)
print("Batch Size for Output Image : ",train[0][1].shape)
print("Image Size of first image : ",train[0][0][0].shape)
print("Output of first image : ",train[0][1][0].shape)

fig , axs = plt.subplots(2,3 ,figsize = (10,10))
axs[0][0].imshow(train[0][0][8])
axs[0][0].set_title(train[0][1][8])
axs[0][1].imshow(train[0][0][10])
axs[0][1].set_title(train[0][1][10])
axs[0][2].imshow(train[0][0][5])
axs[0][2].set_title(train[0][1][5])
axs[1][0].imshow(train[0][0][2])
axs[1][0].set_title(train[0][1][0])
axs[1][1].imshow(train[0][0][7])
axs[1][1].set_title(train[0][1][7])
axs[1][2].imshow(train[0][0][3])
axs[1][2].set_title(train[0][1][3])

"""* Flattening
* Activation Function - Sigmoide
"""

def AlexNet( input_shape, num_classes):
    initializer = tf.keras.initializers.GlorotNormal()
    model = tf.keras.Sequential(name='AlexNet')
    model.add(Conv2D(32, kernel_size=(11,11), strides= 4,
                    padding= 'valid', activation= 'relu',
                    input_shape= input_shape, kernel_initializer= initializer))
    model.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),
                          padding= 'valid', data_format= None))
    model.add(Conv2D(64, kernel_size=(3,3), strides= 1,
                    padding= 'same', activation= 'relu',
                    kernel_initializer= initializer))

    model.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),
                          padding= 'valid', data_format= None))

    model.add(Flatten())
    model.add(Dense(128, activation=tf.nn.sigmoid))
    model.add(Dense(num_classes, activation= 'softmax'))

    model.compile(optimizer = tf.optimizers.Adam(),
                loss = 'categorical_crossentropy',
                metrics = ['accuracy'])
    return model


def train_model(model,valid_generator,train_generator,EPOCHS):   
    history=model.fit(train_generator,
                    epochs=EPOCHS,
                    validation_data=valid_generator,
                    verbose=1)
    return history

num_classes= len(np.unique(train.classes))
model = AlexNet((227, 227, 3), num_classes)
model.summary()

history=train_model(model,validation,train,30)

model.evaluate(validation)

def plot_history(history):
    loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' not in s]
    val_loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' in s]
    acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' not in s]
    val_acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' in s]
    
    if len(loss_list) == 0:
        print('Loss is missing in history')
        return 
    
    ## As loss always exists
    epochs = range(1,len(history.history[loss_list[0]]) + 1)
    
    ## Loss
    plt.figure(1)
    for l in loss_list:
        plt.plot(epochs, history.history[l], 'b', label='Training loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))
    for l in val_loss_list:
        plt.plot(epochs, history.history[l], 'g', label='Validation loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))
    
    plt.title('Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()
    
    ## Accuracy
    plt.figure(2)
    for l in acc_list:
        plt.plot(epochs, history.history[l], 'b', label='Training accuracy (' + str(format(history.history[l][-1],'.5f'))+')')
    for l in val_acc_list:    
        plt.plot(epochs, history.history[l], 'g', label='Validation accuracy (' + str(format(history.history[l][-1],'.5f'))+')')

    plt.title('Accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.show()


plot_history(history)

"""Previsao - NonCOVID"""

# Commented out IPython magic to ensure Python compatibility.
!rm -r *.png
!rm -r *.jpg
# %matplotlib inline
import matplotlib.pyplot as plt
import numpy as np
from google.colab import files
from keras.preprocessing import image

uploaded = files.upload()
total = 0
count_covid = 0
count_noncovid = 0
for fn in uploaded.keys():
  total = total + 1
  path = '/content/' + fn
  img = image.load_img(path, target_size=(227, 227))
  x = image.img_to_array(img)
  plt.imshow(x/255.)
  plt.show()
  x = np.expand_dims(x, axis=0)
  images = np.vstack([x])
  if (model.predict(images) > 0.5).astype("int32")[0][1]<0.5:
    print(fn + " COVID")
    count_covid = count_covid + 1
  else:
    print(fn + " NonCOVID")
    count_noncovid = count_noncovid + 1

print ('total: ' + str(total)) 
print ('covid: ' + str(count_covid))
print ('noncovid: ' + str(count_noncovid))

!zip -r test.zip ./ct-images/test

"""Previsão COVID:"""

# Commented out IPython magic to ensure Python compatibility.
!rm -r *.png
!rm -r *.jpg
# %matplotlib inline
import matplotlib.pyplot as plt
import numpy as np
from google.colab import files
from keras.preprocessing import image

uploaded = files.upload()
total = 0
count_covid = 0
count_noncovid = 0
for fn in uploaded.keys():
  total = total + 1
  path = '/content/' + fn
  img = image.load_img(path, target_size=(227, 227))
  x = image.img_to_array(img)
  plt.imshow(x/255.)
  plt.show()
  x = np.expand_dims(x, axis=0)
  images = np.vstack([x])
  if (model.predict(images) > 0.5).astype("int32")[0][1]<0.5:
    print(fn + " COVID")
    count_covid = count_covid + 1
  else:
    print(fn + " NonCOVID")
    count_noncovid = count_noncovid + 1

print ('total: ' + str(total)) 
print ('covid: ' + str(count_covid))
print ('noncovid: ' + str(count_noncovid))